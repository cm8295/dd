<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>我的GitHub网页</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        header {
            text-align: center;
            padding: 20px 0;
        }
        .content {
            margin: 30px 0;
        }
        footer {
            text-align: center;
            margin-top: 50px;
            color: #666;
        }
        .mic-section {
            margin: 20px 0;
            text-align: center;
        }
        .mic-button {
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 15px 32px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px;
            cursor: pointer;
            border-radius: 4px;
        }
        .mic-button:hover {
            background-color: #45a049;
        }
        .mic-button.recording {
            background-color: #f44336;
        }
        .visualization {
            margin: 20px auto;
            height: 100px;
            width: 100%;
            background-color: #f0f0f0;
        }
    </style>
</head>
<body>
    <header>
        <h1>欢迎来到我的网页</h1>
        <p>这是一个通过 GitHub Pages 托管的网页</p>
    </header>
    
    <div class="content">
        <h2>关于我</h2>
        <p>这里可以添加你的个人介绍、项目说明或其他内容。</p>
        
        <h2>我的项目</h2>
        <ul>
            <li>项目1：这是我的第一个项目</li>
            <li>项目2：这是我的第二个项目</li>
        </ul>
        
        <div class="mic-section">
            <h2>麦克风输入</h2>
            <button id="micButton" class="mic-button">开始录音</button>
            <canvas id="visualization" class="visualization"></canvas>
            <p id="status">点击按钮开始使用麦克风</p>
        </div>
    </div>
    
    <footer>
        <p>© 2023 我的网页 | 托管在 <a href="https://pages.github.com/">GitHub Pages</a></p>
    </footer>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let audioContext;
        let analyser;
        let microphone;
        let canvasContext;
        
        const micButton = document.getElementById('micButton');
        const statusText = document.getElementById('status');
        const visualization = document.getElementById('visualization');
        let canvasCtx;
        
        // Initialize canvas after page load
        window.addEventListener('load', () => {
            canvasCtx = visualization.getContext('2d');
            visualization.width = visualization.offsetWidth;
            visualization.height = visualization.offsetHeight;
        });
        
        micButton.addEventListener('click', async () => {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        });
        
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                statusText.textContent = "正在录音...";
                micButton.textContent = "停止录音";
                micButton.classList.add('recording');
                isRecording = true;
                
                // Create media recorder for actual recording
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.addEventListener("dataavailable", event => {
                    audioChunks.push(event.data);
                });
                
                mediaRecorder.start();
                
                // Setup audio visualization
                setupAudioVisualization(stream);
                
            } catch (error) {
                console.error("Error accessing microphone:", error);
                statusText.textContent = "无法访问麦克风: " + error.message;
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                statusText.textContent = "录音已停止";
                micButton.textContent = "开始录音";
                micButton.classList.remove('recording');
                
                // Stop all audio tracks
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Create audio file from recorded chunks
                mediaRecorder.addEventListener("stop", () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    statusText.innerHTML = `录音完成! <a href="${audioUrl}" download="recording.webm">下载录音</a>`;
                });
            }
        }
        
        function setupAudioVisualization(stream) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            microphone = audioContext.createMediaStreamSource(stream);
            microphone.connect(analyser);
            
            analyser.fftSize = 256;
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            
            function draw() {
                if (!isRecording) return;
                
                requestAnimationFrame(draw);
                
                analyser.getByteFrequencyData(dataArray);
                
                canvasCtx.fillStyle = 'rgb(240, 240, 240)';
                canvasCtx.fillRect(0, 0, visualization.width, visualization.height);
                
                const barWidth = (visualization.width / bufferLength) * 2.5;
                let barHeight;
                let x = 0;
                
                for(let i = 0; i < bufferLength; i++) {
                    barHeight = dataArray[i] / 2;
                    
                    canvasCtx.fillStyle = 'rgb(' + (barHeight+100) + ',50,50)';
                    canvasCtx.fillRect(x, visualization.height - barHeight, barWidth, barHeight);
                    
                    x += barWidth + 1;
                }
            }
            
            draw();
        }
        
        // Handle browser-specific prefixes
        window.AudioContext = window.AudioContext || window.webkitAudioContext;
    </script>
</body>
</html>